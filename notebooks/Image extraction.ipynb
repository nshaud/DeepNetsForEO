{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image extraction\n",
    "This script performs a sliding window on the input images and extracts the\n",
    "smaller patches.\n",
    "It can also perform basic data augmentation (rotations and flips).\n",
    "\n",
    "The dataset is expected to be one or several collections of images (at least\n",
    "the input and the ground truth). Images with the same id should have the same\n",
    "dimensions, e.g. ground_truth_4.tif and top_rgb_4.tif should represent the\n",
    "same tile (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import skimage.transform\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Filter the warnings for low contrast images\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import config values\n",
    "from config import patch_size, step_size, ROTATIONS, FLIPS, DATASET_DIR,\\\n",
    "    DATASET, FOLDER_SUFFIX, BASE_FOLDER, folders, train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window(image, stride=10, window_size=(20,20)):\n",
    "    \"\"\"Extract patches according to a sliding window.\n",
    "\n",
    "    Args:\n",
    "        image (numpy array): The image to be processed.\n",
    "        stride (int, optional): The sliding window stride (defaults to 10px).\n",
    "        window_size(int, int, optional): The patch size (defaults to (20,20)).\n",
    "\n",
    "    Returns:\n",
    "        list: list of patches with window_size dimensions\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # slide a window across the image\n",
    "    for x in range(0, image.shape[0], stride):\n",
    "        for y in range(0, image.shape[1], stride):\n",
    "            new_patch = image[x:x + window_size[0], y:y + window_size[1]]\n",
    "            if new_patch.shape[:2] == window_size:\n",
    "                patches.append(new_patch)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to perform data augmentation if needed (symetries and rotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(patch, flip=False, mirror=False, rotations=[]):\n",
    "    \"\"\"Perform data augmentation on a patch.\n",
    "\n",
    "    Args:\n",
    "        patch (numpy array): The patch to be processed.\n",
    "        flip (bool, optional): Up/down symetry.\n",
    "        mirror (bool, optional): left/right symetry.\n",
    "        rotations (int list, optional) : rotations to perform (angles in deg).\n",
    "\n",
    "    Returns:\n",
    "        array list: list of augmented patches\n",
    "    \"\"\"\n",
    "    transformed_patches = [patch]\n",
    "    for angle in rotations:\n",
    "        transformed_patches.append(skimage.img_as_ubyte(skimage.transform.rotate(patch, angle)))\n",
    "    if flip:\n",
    "        transformed_patches.append(np.flipud(patch))\n",
    "    if mirror:\n",
    "        transformed_patches.append(np.fliplr(patch))\n",
    "    return transformed_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(DATASET_DIR):\n",
    "    os.mkdir(DATASET_DIR)\n",
    "else:\n",
    "    raise Exception(\"Directory exists, aborted.\"\n",
    "                    \" Add a specific suffix or remove existing directory with\"\n",
    "                    \" same parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We write the relevant parameters in a text file\n",
    "details_file = open(DATASET_DIR + 'details.txt', 'w')\n",
    "details_file.write('Dataset : ' + DATASET + '\\n')\n",
    "details_file.write('Training tiles : {}\\n'.format(train_ids))\n",
    "details_file.write('Testing tiles : {}\\n'.format(test_ids))\n",
    "details_file.write('Sliding window patch size : ({},{})'.format(*patch_size))\n",
    "details_file.write('Sliding window stride : {}'.format(step_size))\n",
    "details_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for suffix, folder, files in tqdm(folders):\n",
    "    tqdm.write((\"=== PROCESSING {} ===\").format(suffix.upper()))\n",
    "\n",
    "    # We create the subfolders splitted in train and test\n",
    "    os.mkdir(DATASET_DIR + suffix + '_train')\n",
    "    os.mkdir(DATASET_DIR + suffix + '_test')\n",
    "\n",
    "    # Generate generators to read the iamges\n",
    "    train_dataset = (io.imread(folder + files.format(*id_)) for id_ in train_ids)\n",
    "    test_dataset = (io.imread(folder + files.format(*id_)) for id_ in test_ids)\n",
    "\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    for image in tqdm(train_dataset):\n",
    "        # Use the sliding window to extract the patches\n",
    "        for patches in sliding_window(image, window_size=patch_size, stride=step_size):\n",
    "            # Append the augmented patches to the sequence\n",
    "            train_samples.extend(transform(patches, flip=FLIPS[0], mirror=FLIPS[1], rotations=ROTATIONS))\n",
    "\n",
    "    for image in tqdm(test_dataset):\n",
    "        # Same as the previous loop, but without data augmentation (test dataset)\n",
    "        # Sliding window with no overlap\n",
    "        for patches in sliding_window(image, window_size=patch_size, stride=patch_size[0]):\n",
    "            test_samples.extend(transform(patches))\n",
    "\n",
    "    # We save the images on disk\n",
    "    for i, sample in tqdm(enumerate(train_samples), total=len(train_samples), desc=\"Saving train samples\"):\n",
    "        io.imsave('{}/{}.png'.format(DATASET_DIR + suffix + '_train', i), sample)\n",
    "\n",
    "    tqdm.write(\"({} training set: done)\".format(suffix))\n",
    "\n",
    "    for i, sample in tqdm(enumerate(test_samples), total=len(test_samples), desc=\"Saving test samples\"):\n",
    "        io.imsave('{}/{}.png'.format(DATASET_DIR + suffix + '_test', i), sample)\n",
    "    tqdm.write(\"({} testing set: done)\".format(suffix))\n",
    "\n",
    "\n",
    "print \"All done ! The dataset has been saved in {}.\".format(DATASET_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
